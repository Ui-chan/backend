from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from django.utils import timezone
from django.db.models import Avg, Count, Sum, F, Case, When
from django.db.models.functions import TruncDate
from collections import defaultdict
from google.cloud import vision
import base64
from .serializers import * # ìƒˆë¡œ ì¶”ê°€
import google.generativeai as genai
import os
import json
from dotenv import load_dotenv
from openai import OpenAI

from games.models import GameSession, GameInteractionLog 
from .models import ChecklistResult
from users.models import User  
from .serializers import *
from datetime import date # <<<<<<< 1. ì´ ë¶€ë¶„ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.


# â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼â–¼
class DateEncoder(json.JSONEncoder):
    """ date ê°ì²´ë¥¼ JSONìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•œ í´ë˜ìŠ¤ """
    def default(self, o):
        if isinstance(o, date):
            return o.isoformat() # date ê°ì²´ë¥¼ 'YYYY-MM-DD' í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
        return super().default(o)
# â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²

def _generate_comprehensive_stats(user_id: int) -> dict:
    """
    ì£¼ì–´ì§„ ì‚¬ìš©ìì— ëŒ€í•œ ì¢…í•© í†µê³„ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜)
    
    Args:
        user_id (int): í†µê³„ë¥¼ ìƒì„±í•  ì‚¬ìš©ìì˜ ID

    Returns:
        dict: ëª¨ë“  ê²Œì„ì— ëŒ€í•œ êµ¬ì¡°í™”ëœ í†µê³„ ë°ì´í„°ê°€ ë‹´ê¸´ ë”•ì…”ë„ˆë¦¬
    """
    today = timezone.now().date()

    sessions = GameSession.objects.filter(user_id=user_id)
    if not sessions.exists():
        # ì‚¬ìš©ìì˜ ê²Œì„ ê¸°ë¡ì´ ì—†ëŠ” ê²½ìš°, ê¸°ë³¸ ë°ì´í„° êµ¬ì¡°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        default_assistance = {'NONE': 0, 'VERBAL': 0, 'PHYSICAL': 0}
        return {
            'game1': {'today_attempts': 0, 'today_success_rate': 0, 'today_play_duration_seconds': 0, 'overall_avg_success_rate': 0, 'overall_avg_response_time': 0, 'daily_success_rate_trend': [], 'daily_response_time_trend': [], 'success_rate_by_assistance': default_assistance},
            'game2': {'today_play_count': 0, 'today_play_duration_seconds': 0, 'today_avg_response_time': 0, 'overall_avg_response_time': 0, 'avg_daily_play_time_seconds': 0, 'daily_response_time_trend': [], 'play_time_by_assistance': default_assistance},
            'game3': {'today_attempts': 0, 'today_success_rate': 0, 'today_play_duration_seconds': 0, 'overall_avg_success_rate': 0, 'daily_success_rate_trend': [], 'daily_avg_power_trend': [], 'success_rate_by_assistance': default_assistance, 'avg_power_by_assistance': default_assistance}
        }
        
    session_assistance_map = {s.session_id: s.assistance_level for s in sessions}
    logs = GameInteractionLog.objects.filter(session_id__in=sessions.values_list('session_id', flat=True))

    # --- ê²Œì„ 1: ì €ê¸° ë´! ---
    g1_sessions = sessions.filter(game_id=1)
    g1_logs = logs.filter(session_id__in=g1_sessions.values_list('session_id', flat=True))
    g1_today_logs = g1_logs.filter(timestamp__date=today)
    g1_today_sessions = g1_sessions.filter(session_start_time__date=today, session_end_time__isnull=False)
    g1_today_duration_agg = g1_today_sessions.aggregate(total=Sum(F('session_end_time') - F('session_start_time')))['total']
    
    daily_success_rate_trend_g1 = list(g1_logs.annotate(date=TruncDate('timestamp')).values('date').annotate(s=Count(Case(When(is_successful=True, then=1))), t=Count('log_id')).annotate(value=F('s')*100.0/F('t')).values('date', 'value').order_by('date'))
    daily_response_time_trend_g1 = list(g1_logs.filter(response_time_ms__isnull=False).annotate(date=TruncDate('timestamp')).values('date').annotate(value=Avg('response_time_ms')).values('date', 'value').order_by('date'))
    
    g1_assistance_success = defaultdict(int)
    g1_assistance_total = defaultdict(int)
    for log in g1_logs:
        level = session_assistance_map.get(log.session_id)
        if level:
            g1_assistance_total[level] += 1
            if log.is_successful: g1_assistance_success[level] += 1
    
    g1_stats = {
        'today_attempts': g1_today_logs.count(),
        'today_success_rate': (g1_today_logs.filter(is_successful=True).count() / g1_today_logs.count() * 100) if g1_today_logs.count() > 0 else 0,
        'today_play_duration_seconds': g1_today_duration_agg.total_seconds() if g1_today_duration_agg else 0,
        'overall_avg_success_rate': (g1_logs.filter(is_successful=True).count() / g1_logs.count() * 100) if g1_logs.count() > 0 else 0,
        'overall_avg_response_time': g1_logs.aggregate(avg=Avg('response_time_ms'))['avg'] or 0,
        'daily_success_rate_trend': daily_success_rate_trend_g1,
        'daily_response_time_trend': daily_response_time_trend_g1,
        'success_rate_by_assistance': { level: (g1_assistance_success[level] / g1_assistance_total[level] * 100) if g1_assistance_total[level] > 0 else 0 for level in ['NONE', 'VERBAL', 'PHYSICAL'] }
    }

    # --- ê²Œì„ 2: í‘œì • ì§“ê¸° ---
    g2_sessions = sessions.filter(game_id=2)
    g2_logs = logs.filter(session_id__in=g2_sessions.values_list('session_id', flat=True))
    daily_response_time_trend_g2 = list(
        g2_logs
        .filter(response_time_ms__isnull=False)
        .annotate(date=TruncDate('timestamp'))
        .values('date')
        .annotate(value=Avg('response_time_ms'))
        .values('date', 'value')
        .order_by('date')
    )
    g2_today_sessions = g2_sessions.filter(session_start_time__date=today, session_end_time__isnull=False)
    today_play_duration_agg = g2_today_sessions.aggregate(total=Sum(F('session_end_time') - F('session_start_time')))['total']
    total_play_time_agg = g2_sessions.exclude(session_end_time__isnull=True).aggregate(total=Sum(F('session_end_time') - F('session_start_time')))['total']
    total_play_days = g2_sessions.annotate(date=TruncDate('session_start_time')).values('date').distinct().count()

    # âœ… ë‚ ì§œë³„ í”Œë ˆì´ ì‹œê°„ ì¶”ì´ ê³„ì‚°
    daily_g2_play_time = (
        g2_sessions
        .exclude(session_end_time__isnull=True)
        .annotate(date=TruncDate('session_start_time'))
        .values('date')
        .annotate(total_duration=Sum(F('session_end_time') - F('session_start_time')))
    )

    daily_play_time_trend_g2 = [
        {
            'date': entry['date'],
            'value': entry['total_duration'].total_seconds() if entry['total_duration'] else 0
        }
        for entry in daily_g2_play_time
    ]

    g2_stats = {
        'today_play_count': g2_today_sessions.count(),
        'today_play_duration_seconds': today_play_duration_agg.total_seconds() if today_play_duration_agg else 0,
        'today_avg_response_time': g2_logs.filter(timestamp__date=today).aggregate(avg=Avg('response_time_ms'))['avg'] or 0,
        'overall_avg_response_time': g2_logs.aggregate(avg=Avg('response_time_ms'))['avg'] or 0,
        'avg_daily_play_time_seconds': (total_play_time_agg.total_seconds() / total_play_days) if total_play_days > 0 else 0,
        'daily_response_time_trend': daily_response_time_trend_g2,
        'daily_play_time_trend': daily_play_time_trend_g2,  # âœ… ìƒˆ í•„ë“œ ì¶”ê°€
        'play_time_by_assistance': {
            level: (
                g2_sessions
                .filter(assistance_level=level, session_end_time__isnull=False)
                .aggregate(total=Sum(F('session_end_time') - F('session_start_time')))['total']
                .total_seconds()
            ) if g2_sessions.filter(assistance_level=level).exists() else 0
            for level in ['NONE', 'VERBAL', 'PHYSICAL']
        }
    }
    
    # --- ê²Œì„ 3: ê³µ ì£¼ê³ ë°›ê¸° ---
    g3_sessions = sessions.filter(game_id=3)
    g3_logs = logs.filter(session_id__in=g3_sessions.values_list('session_id', flat=True))
    g3_today_logs = g3_logs.filter(timestamp__date=today)
    g3_today_sessions = g3_sessions.filter(session_start_time__date=today, session_end_time__isnull=False)
    g3_today_duration_agg = g3_today_sessions.aggregate(total=Sum(F('session_end_time') - F('session_start_time')))['total']

    daily_g3_success_rate_trend = list(g3_logs.annotate(date=TruncDate('timestamp')).values('date').annotate(s=Count(Case(When(is_successful=True, then=1))), t=Count('log_id')).annotate(value=F('s')*100.0/F('t')).values('date', 'value').order_by('date'))
    
    daily_power_data, g3_assistance_power = defaultdict(lambda: {'total': 0, 'count': 0}), defaultdict(lambda: {'total': 0, 'count': 0})
    g3_assistance_success, g3_assistance_total = defaultdict(int), defaultdict(int)
    for log in g3_logs:
        power = log.interaction_data.get('throw_power')
        if power is not None:
            date = log.timestamp.date()
            daily_power_data[date]['total'] += power
            daily_power_data[date]['count'] += 1
        level = session_assistance_map.get(log.session_id)
        if level:
            g3_assistance_total[level] += 1
            if log.is_successful: g3_assistance_success[level] += 1
            if power is not None:
                g3_assistance_power[level]['total'] += power
                g3_assistance_power[level]['count'] += 1

    daily_avg_power_trend = [{'date': date, 'value': data['total'] / data['count']} for date, data in sorted(daily_power_data.items())]

    g3_stats = {
        'today_attempts': g3_today_logs.count(),
        'today_success_rate': (g3_today_logs.filter(is_successful=True).count() / g3_today_logs.count() * 100) if g3_today_logs.count() > 0 else 0,
        'today_play_duration_seconds': g3_today_duration_agg.total_seconds() if g3_today_duration_agg else 0,
        'overall_avg_success_rate': (g3_logs.filter(is_successful=True).count() / g3_logs.count() * 100) if g3_logs.count() > 0 else 0,
        'daily_success_rate_trend': daily_g3_success_rate_trend,
        'daily_avg_power_trend': daily_avg_power_trend,
        'success_rate_by_assistance': { level: (g3_assistance_success[level] / g3_assistance_total[level] * 100) if g3_assistance_total[level] > 0 else 0 for level in ['NONE', 'VERBAL', 'PHYSICAL'] },
        'avg_power_by_assistance': { level: (data['total'] / data['count']) if data['count'] > 0 else 0 for level, data in g3_assistance_power.items() }
    }
    
    # ìµœì¢… ë°ì´í„° êµ¬ì¡°í™”
    processed_data = {'game1': g1_stats, 'game2': g2_stats, 'game3': g3_stats }
    return processed_data


class SaveChecklistResultView(APIView):
    def post(self, request, *args, **kwargs):
        serializer = ChecklistResultSerializer(data=request.data)
        if serializer.is_valid():
            serializer.save()
            return Response({"message": "Checklist result saved successfully."}, status=status.HTTP_201_CREATED)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

class GetChecklistHistoryView(APIView):
    def post(self, request, *args, **kwargs):
        serializer = HistoryRequestSerializer(data=request.data)
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        user_id = serializer.validated_data['user_id']
        history = ChecklistResult.objects.filter(user_id=user_id)
        history_serializer = ChecklistResultSerializer(history, many=True)
        return Response(history_serializer.data, status=status.HTTP_200_OK)

class ComprehensiveStatsView(APIView):
    """
    ì‚¬ìš©ìì˜ í†µê³„ ë°ì´í„°ì™€ ì €ì¥ëœ AI ë¶„ì„ ê²°ê³¼ë¥¼ í•¨ê»˜ ë°˜í™˜í•˜ëŠ” API
    """
    def post(self, request, *args, **kwargs):
        # 1. ìš”ì²­ ë°ì´í„° ê²€ì¦
        req_serializer = StatsRequestSerializer(data=request.data)
        if not req_serializer.is_valid():
            return Response(req_serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
        user_id = req_serializer.validated_data['user_id']
        
        # 2. í—¬í¼ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ í†µê³„ ë°ì´í„° ìƒì„±
        statistics_data = _generate_comprehensive_stats(user_id)
        
        # 3. User ëª¨ë¸ì—ì„œ AI ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
        try:
            user = User.objects.get(user_id=user_id)
            analysis_data = {
                'game1_analysis': user.game1_analysis,
                'game2_analysis': user.game2_analysis,
                'game3_analysis': user.game3_analysis,
            }
        except User.DoesNotExist:
            # ì‚¬ìš©ìê°€ ì—†ìœ¼ë©´ ë¶„ì„ ê²°ê³¼ëŠ” ë¹„ì›Œë‘¡ë‹ˆë‹¤.
            analysis_data = {
                'game1_analysis': {},
                'game2_analysis': {},
                'game3_analysis': {},
            }

        # 4. í†µê³„ ë°ì´í„°ì™€ ë¶„ì„ ê²°ê³¼ë¥¼ í•©ì³ ìµœì¢… ì‘ë‹µ ë°ì´í„° êµ¬ì¡° ìƒì„±
        response_data = {
            'statistics': statistics_data,
            **analysis_data  # ë”•ì…”ë„ˆë¦¬ í•©ì¹˜ê¸°
        }
        
        # 5. ìƒˆë¡œ ë§Œë“  ìµœìƒìœ„ ì‹œë¦¬ì–¼ë¼ì´ì €ë¡œ ê²°ê³¼ ì§ë ¬í™” ë° ë°˜í™˜
        serializer = UserStatsWithAnalysisSerializer(data=response_data)
        serializer.is_valid(raise_exception=True)
        return Response(serializer.data, status=status.HTTP_200_OK)
    

class DetectEmotionView(APIView):
    """
    ì´ë¯¸ì§€, ëª©í‘œ ê°ì •, ê·¸ë¦¬ê³  ë°˜ì‘ ì‹œê°„ì„ ë°›ì•„ ì¼ì¹˜ ì—¬ë¶€ë¥¼ ë¶„ì„í•˜ëŠ” API
    """
    def post(self, request, *args, **kwargs):
        # ì´ì œ Serializerê°€ image, target_emotion, response_time_msë¥¼ ëª¨ë‘ ê²€ì¦í•©ë‹ˆë‹¤.
        serializer = DetectEmotionSerializer(data=request.data)
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        image_data = serializer.validated_data['image']
        target_emotion = serializer.validated_data['target_emotion']
        response_time_ms = serializer.validated_data['response_time_ms']
        # response_time_ms ê°’ë„ validated_dataì— í¬í•¨ë˜ì§€ë§Œ, ì´ Viewì˜ í•µì‹¬ ë¡œì§(ê°ì • ë¶„ì„)ì—ëŠ”
        # ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë”°ë¡œ ë³€ìˆ˜ë¡œ ì¶”ì¶œí•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤. 
        # ë§Œì•½ ì´ ê°’ì„ DBì— ì €ì¥í•˜ê±°ë‚˜ ë‹¤ë¥¸ ìš©ë„ë¡œ ì‚¬ìš©í•˜ë ¤ë©´ ì•„ë˜ì™€ ê°™ì´ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # response_time_ms = serializer.validated_data['response_time_ms']
            
        header, encoded = image_data.split(",", 1)
        image_content = base64.b64decode(encoded)

        client = vision.ImageAnnotatorClient()
        image = vision.Image(content=image_content)
        response = client.face_detection(image=image)
        face_annotations = response.face_annotations

        if not face_annotations:
            return Response({"error": "No face detected"}, status=status.HTTP_400_BAD_REQUEST)

        likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE', 'LIKELY', 'VERY_LIKELY')
        emotions = face_annotations[0]
        
        target_likelihood_str = 'UNKNOWN'
        is_match = False

        if target_emotion == 'happy':
            target_likelihood_str = likelihood_name[emotions.joy_likelihood]
            is_match = target_likelihood_str in ['POSSIBLE', 'LIKELY', 'VERY_LIKELY']

        elif target_emotion == 'sad':
            target_likelihood_str = likelihood_name[emotions.sorrow_likelihood]
            is_match = target_likelihood_str in ['POSSIBLE', 'LIKELY', 'VERY_LIKELY']

        elif target_emotion == 'surprised':
            target_likelihood_str = likelihood_name[emotions.surprise_likelihood]
            is_match = target_likelihood_str in ['POSSIBLE', 'LIKELY', 'VERY_LIKELY']

        elif target_emotion == 'angry':
            target_likelihood_str = likelihood_name[emotions.anger_likelihood]
            is_match = target_likelihood_str in ['POSSIBLE', 'LIKELY', 'VERY_LIKELY']
        
        return Response({
            "detected_emotion": target_emotion,
            "target_emotion" : target_emotion,
            "is_match": is_match,
            "response_time_ms" : response_time_ms,
            "target_likelihood": target_likelihood_str
        }, status=status.HTTP_200_OK)
    
class AnalyzeAndSaveStatsView(APIView):
    """
    ì‚¬ìš©ìì˜ í†µê³„ ë°ì´í„°ë¥¼ Gemini AIë¡œ ë¶„ì„í•˜ê³  ê·¸ ê²°ê³¼ë¥¼ DBì— ì €ì¥í•˜ëŠ” API.
    """
    def post(self, request, *args, **kwargs):
        req_serializer = StatsRequestSerializer(data=request.data)
        if not req_serializer.is_valid():
            return Response(req_serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
        user_id = 2 # ìš”ì²­ì—ì„œëŠ” user_id=2ë¥¼ ì‚¬ìš©

        # 1. í†µê³„ ë°ì´í„° ìƒì„±
        try:
            stats_data = _generate_comprehensive_stats(user_id)
            if not stats_data or not stats_data.get('game1'):
                 return Response({"error": f"User ID {user_id}ì— ëŒ€í•œ í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({"error": f"í†µê³„ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        # 2. Gemini í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ğŸ¤–
        try:
            gemini_api_key = os.getenv("GEMINI_API_KEY")
            if not gemini_api_key:
                raise ValueError("GEMINI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            genai.configure(api_key=gemini_api_key)
        except Exception as e:
            return Response({"error": f"Gemini í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        analysis_results = {}
        generation_config = {"response_mime_type": "application/json"} # JSON ì¶œë ¥ ëª¨ë“œ ì„¤ì •
        model = genai.GenerativeModel('gemini-1.5-pro-latest') # ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ

        # 3. ê° ê²Œì„ë³„ë¡œ AI ë¶„ì„ ìˆ˜í–‰
        for game_key, game_data in stats_data.items():
            prompt = self.create_analysis_prompt(game_key, game_data)

            try:
                # Gemini API í˜¸ì¶œ
                response = model.generate_content(
                    prompt,
                    generation_config=generation_config
                )
                
                # Gemini ì‘ë‹µ(JSON í˜•ì‹)ì„ íŒŒì‹±
                ai_response_content = response.text
                analysis_results[game_key] = json.loads(ai_response_content)

            except Exception as e:
                return Response({"error": f"{game_key} ë¶„ì„ ì¤‘ Gemini API ì˜¤ë¥˜ ë°œìƒ: {e}"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        # 4. ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        try:
            user = User.objects.get(user_id=user_id)
            user.game1_analysis = analysis_results.get('game1', {})
            user.game2_analysis = analysis_results.get('game2', {})
            user.game3_analysis = analysis_results.get('game3', {})
            user.save()
        except User.DoesNotExist:
            return Response({"error": f"User ID {user_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}, status=status.HTTP_404_NOT_FOUND)
        except Exception as e:
            return Response({"error": f"ë¶„ì„ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

        # 5. ì„±ê³µ ì‘ë‹µ ë°˜í™˜
        return Response({
            "message": f"User ID {user_id}ì— ëŒ€í•œ Gemini AI ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆê³  ê²°ê³¼ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "analysis_results": analysis_results
        }, status=status.HTTP_200_OK)

    def create_analysis_prompt(self, game_key: str, game_data: dict) -> str:
        """AI ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í—¬í¼ ë©”ì„œë“œ"""
        game_name_map = {
            'game1': 'Look at That! (Attention & Eye Contact)',
            'game2': 'Making Faces (Emotional Expression)',
            'game3': 'Ball Toss (Interaction & Motor Skills)'
        }
        game_name = game_name_map.get(game_key, game_key)
        data_string = json.dumps(game_data, indent=4, ensure_ascii=False, cls=DateEncoder)

        prompt = f"""
        You are an expert data analyst for developmental games designed to help children with Autism Spectrum Disorder (ASD). 
        You must respond in a warm, hopeful, and encouraging tone so that parents can easily understand and be encouraged by their child's growth.

        The following is the statistical data for a child's performance in the '{game_name}' game.

        Data:
        ```json
        {data_string}
        ```

        Based on this data, please find **one positive feature or notable point** that best showcases the child's effort and growth. 
        Summarize this feature as a message for the parents in **exactly 3 lines, including key numerical values**.

        (Example: 'Today, your child showed wonderful concentration. Notably, their success rate reached 70% with only verbal help (VERBAL), which is a positive sign that their willingness to listen to instructions and try things on their own is growing stronger. Consistently praising this type of interaction will be a great help in boosting their confidence.')

        The analysis must be provided in English and formatted as a JSON object (`"response_mime_type": "application/json"`) as requested. The output JSON object must have the following key:
        - "notable_points"
        """
        return prompt